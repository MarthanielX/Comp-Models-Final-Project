{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sunday 10/21:\n",
    "\n",
    "- Set deadlines for when certain things should be done by\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monday 10/22:\n",
    "\n",
    "- Created the repository and the ReadMe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sunday 10/28:\n",
    "\n",
    "- Tried to figure out what we should do about dangling links when making the matrices (which occur when people produce a target that was never tested as a cue) \n",
    "- Decided on two options: \n",
    "1. a matrix that just ignores dangling links (and in the case of a stochstic matrix normalizes the remaining values to sum to 1)\n",
    "2. a matrix with entries for the dangling links. We talked about just having no out-edges from nodes corresponding to the dangling links. But now I'm thinking we could just give them links to all other nodes (with weights uniformly distributed in the case of a stochastic matrix)\n",
    "\n",
    "- I wrote the functions to create the matrices for the first option\n",
    "\n",
    "- We also discussed what form to load in the data in. We decided on a dict mapping cues to targets, a list of the cues, and list of the unnormed targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monday 10/29:\n",
    "\n",
    "- Wrote methods to create the matrices (boolean and stochastic) for the second option from above. So the matrix has rows/cols for the dangling links, but right now these nodes have no out-going edges. \n",
    "- Immediate Next Step: we still have to decide what we'll do with dangling links and code it up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wednesday 10/31:\n",
    "\n",
    "- Decided to give the nodes corresponding to unnormed cues out-edges to all other nodes (all equally weighted in the case of the stocahstic matrix)\n",
    "- Updated the createFullMatrix methods to reflect this decision\n",
    "- Noticed that these unnormed nodes shouldn't have out-edges to themselves, so updated method to reflect this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sunday 11/4:\n",
    "\n",
    "- Discussed how to get the files storing the matrices to be small enough to be pushed to github\n",
    "- Decided to just re-compute these matrices each time for now, since it only takes a few minutes and we weren't able to find an easy way of compressing the files further\n",
    "- Checked to make sure the matrices being computed were correct\n",
    "- Carefully read through the PageRank chapters of $\\textit{Google's PageRank and Beyond: The Science of Search Engine Rankings}$ (https://muse.jhu.edu/book/36229/)\n",
    "- Next Step: Begin Immplementing PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sunday 11/11:\n",
    "    \n",
    "- Wrote a function to load the two types of retrievability data. The K&F frequency is the frequency that words showd up in a text sample of about a million words, due to Kucera & Francis (1967). The accessibility index of a word x is the number of cues for which at leasrt 1 person produced x. \n",
    "- Wrote some tests below to make sure the dictionaries are actually being loaded correctly\n",
    "- Realized that the Griffiths et al. paper doesn't have their full data set and that the K&F data is word frequency in text, not from a similar procedure to Griffiths et al.'s. This is concerning because we then don't anything to evaluate our models' performances against. Searched Grifiths's page and elsewhere on the internet for similar data sets (keyword: phonemic fluency task), but wasn't able to find any trials done on healthy adults. \n",
    "- Next Steps: Need to find a way of evaluating our models. Possibilites: \n",
    "    - Use the partial data in Griffiths paper, which only has 7 letters. It has the human frequencies for the top 10 words, and the frequencies for the top 10 words predicted by each model. \n",
    "    - Find some other dataset somewhere online\n",
    "    - Run the experiment ourselves and gather our own data\n",
    "    - Compare against some other metric besides the human production frequency (I hate this idea unless we can find something really closely related.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import accessibility_loader\n",
    "\n",
    "kf_frequencies, accessibility_indices = accessibility_loader.loadDicts()\n",
    "#print(\"food:\", kf_frequencies['food'], accessibility_indices['food'])\n",
    "#print(\"money:\", kf_frequencies['money'], accessibility_indices['money'])\n",
    "#print(\"water:\", kf_frequencies['water'], accessibility_indices['water'])\n",
    "\n",
    "assert(kf_frequencies['night'] == 411)\n",
    "assert(accessibility_indices['night'] == 55)\n",
    "\n",
    "assert(kf_frequencies['bar'] == 82)\n",
    "assert(accessibility_indices['bar'] == 46)\n",
    "\n",
    "assert(kf_frequencies['fake'] == 10)\n",
    "assert(accessibility_indices['fake'] == 46)\n",
    "\n",
    "assert(kf_frequencies['grandparents'] == 3)\n",
    "assert(accessibility_indices['grandparents'] == 2)\n",
    "\n",
    "assert(kf_frequencies['man'] == 1207)\n",
    "assert(accessibility_indices['man'] == 171)\n",
    "\n",
    "assert(kf_frequencies.get('asdfasdf') == None)\n",
    "assert(accessibility_indices.get('asdfasdfas') == None)\n",
    "assert(kf_frequencies.get('devices') == None)\n",
    "assert(kf_frequencies.get('peal') == None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monday 11/12:\n",
    "\n",
    "- Went of office hours to talk the problem through with Anna. She suggested to use Griffiths partial data. She said we could run the experiment ourselves but she wouldn't recommend it unless we want to. Decided to run the experiment ourselves.  \n",
    "- Created a google form to run the experiment (with Luna)\n",
    "- After a trial on a few people, decided on the final experimental procedure: \n",
    "    - record name and gender\n",
    "    - run through all the letters in a random order, twice\n",
    "    - skipped the same letters as Griffiths et al. (K, Q, X, Y, Z)\n",
    "    - \"You're going to see a letter on the screen, and for each one, tell me first word starting with the letter than comes into your head.\"\n",
    "    - Decided that any first word is ok, even if it is \"inappropriate\", a proper noun, or a repetition from teh first trial. However, non-English words are not allowed.\n",
    "    - Let the participant read the letter off the screen so as not to confuse them. People kept thinking \"eye\" when I would say \"I\", \"You\" when I would say \"U\", etc. Zoom in to 500% in the browser so they participant can only see 1 letter at a time. \n",
    "    - When they say a word, I type it in and then tab to the next letter.\n",
    "- Ran the experiment on roughly 25 people. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
